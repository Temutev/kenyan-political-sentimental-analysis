{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tevin/Desktop/Tems/twitter/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-09-21 11:59:11.815688: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-21 11:59:17.007339: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load our libraries \n",
    "import pandas as pd \n",
    "import os\n",
    "import os\n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from wordcloud import STOPWORDS\n",
    "from collections import defaultdict\n",
    "\n",
    "from wordcloud import WordCloud,ImageColorGenerator\n",
    "from PIL import Image\n",
    "import urllib\n",
    "import requests\n",
    "\n",
    "\n",
    "from transformers import pipeline\n",
    "sentiment_analysis = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#function to join all csv files in a folder\n",
    "def join_csv_files(folder_path):\n",
    "    # Initialize an empty DataFrame to store the combined data\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            # Construct the full path to the CSV file\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Concatenate the current DataFrame with the combined DataFrame\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/home/tevin/Desktop/Tems/twitter/data/'\n",
    "\n",
    "combined_df = join_csv_files(folder_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13999, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the shape of our data\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get specific columns for our analysis\n",
    "combined_df = combined_df[['full_text','reply_count','retweet_count','favorite_count','url','created_at','view_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>url</th>\n",
       "      <th>created_at</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On each of your birthdays like today, I reflec...</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>3407.0</td>\n",
       "      <td>36751.0</td>\n",
       "      <td>https://twitter.com/RailaOdinga/status/1562362...</td>\n",
       "      <td>2022-08-24T08:52:26.000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We have always stood for the the rule of law a...</td>\n",
       "      <td>4865.0</td>\n",
       "      <td>5897.0</td>\n",
       "      <td>33052.0</td>\n",
       "      <td>https://twitter.com/RailaOdinga/status/1566751...</td>\n",
       "      <td>2022-09-05T11:34:16.000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://t.co/WvnrqktLC4</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>2778.0</td>\n",
       "      <td>27539.0</td>\n",
       "      <td>https://twitter.com/RailaOdinga/status/1565611...</td>\n",
       "      <td>2022-09-02T08:06:02.000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why I won’t be available for William Ruto's in...</td>\n",
       "      <td>4826.0</td>\n",
       "      <td>3927.0</td>\n",
       "      <td>26942.0</td>\n",
       "      <td>https://twitter.com/RailaOdinga/status/1569373...</td>\n",
       "      <td>2022-09-12T17:13:35.000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Back to winning ways! \\n\\nWell in @Arsenal ! h...</td>\n",
       "      <td>1219.0</td>\n",
       "      <td>3022.0</td>\n",
       "      <td>23222.0</td>\n",
       "      <td>https://twitter.com/RailaOdinga/status/1442178...</td>\n",
       "      <td>2021-09-26T17:25:28.000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  reply_count  \\\n",
       "0  On each of your birthdays like today, I reflec...       1884.0   \n",
       "1  We have always stood for the the rule of law a...       4865.0   \n",
       "2                            https://t.co/WvnrqktLC4       2084.0   \n",
       "3  Why I won’t be available for William Ruto's in...       4826.0   \n",
       "4  Back to winning ways! \\n\\nWell in @Arsenal ! h...       1219.0   \n",
       "\n",
       "   retweet_count  favorite_count  \\\n",
       "0         3407.0         36751.0   \n",
       "1         5897.0         33052.0   \n",
       "2         2778.0         27539.0   \n",
       "3         3927.0         26942.0   \n",
       "4         3022.0         23222.0   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://twitter.com/RailaOdinga/status/1562362...   \n",
       "1  https://twitter.com/RailaOdinga/status/1566751...   \n",
       "2  https://twitter.com/RailaOdinga/status/1565611...   \n",
       "3  https://twitter.com/RailaOdinga/status/1569373...   \n",
       "4  https://twitter.com/RailaOdinga/status/1442178...   \n",
       "\n",
       "                 created_at  view_count  \n",
       "0  2022-08-24T08:52:26.000Z         NaN  \n",
       "1  2022-09-05T11:34:16.000Z         NaN  \n",
       "2  2022-09-02T08:06:02.000Z         NaN  \n",
       "3  2022-09-12T17:13:35.000Z         NaN  \n",
       "4  2021-09-26T17:25:28.000Z         NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_text          object\n",
       "reply_count       float64\n",
       "retweet_count     float64\n",
       "favorite_count    float64\n",
       "url                object\n",
       "created_at         object\n",
       "view_count        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check for missing values and filter rows\n",
    "combined_df = combined_df[~combined_df['url'].fillna('').str.contains('apify')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13399, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['created_at'] = pd.to_datetime(combined_df['created_at'])\n",
    "\n",
    "combined_df.sort_values(by=['created_at'], inplace=True, ascending=True)\n",
    "\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (240 > 128). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n",
      "Error processing text.\n"
     ]
    }
   ],
   "source": [
    "# get sentiment label\n",
    "def get_sentiment_label(text):\n",
    "    try:\n",
    "        return sentiment_analysis(text)[0]['label']\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text.\")\n",
    "        return None  # or return a default label or handle the error as needed\n",
    "\n",
    "combined_df['sentiment'] = combined_df['full_text'].apply(get_sentiment_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a copy of the processed dataframe for later use \n",
    "combined_df.to_csv('processed_tweets.csv', index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
